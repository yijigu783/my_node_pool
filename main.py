import requests
import base64
import re
import json
import urllib.parse
import random

# ã€å·²æ›´æ–°ã€‘ä½ æŒ‡å®šçš„ 8 ä¸ªè®¢é˜…æº
URLS = [
    "https://raw.githubusercontent.com/ebrasha/free-v2ray-public-list/refs/heads/main/all_extracted_configs.txt",
    "https://raw.githubusercontent.com/anaer/Sub/main/clash.yaml",
    "https://raw.githubusercontent.com/Pawdroid/Free-servers/main/sub",
    "https://raw.githubusercontent.com/free-nodes/v2rayfree/main/v2",
    "https://raw.githubusercontent.com/free-nodes/clashfree/main/clash.yml",
    "https://bulinkbulink.com/freefq/free/master/v2",
    "https://raw.githubusercontent.com/chengaopan/AutoMergePublicNodes/master/list.txt",
    "https://raw.githubusercontent.com/crossxx-labs/free-proxy/main/clash/vmess.yml"
]

# å…³é”®è¯æ˜ å°„ï¼šè‡ªåŠ¨è¯†åˆ«å›½å®¶
KEYWORD_MAP = {
    'HK': ['hk', 'hongkong', 'hong kong', 'é¦™', 'æ¸¯'],
    'JP': ['jp', 'japan', 'tokyo', 'osaka', 'æ—¥'],
    'US': ['us', 'united states', 'america', 'ç¾', 'los angeles'],
    'SG': ['sg', 'singapore', 'æ–°', 'ç‹®åŸ'],
    'TW': ['tw', 'taiwan', 'taipei', 'å°'],
    'KR': ['kr', 'korea', 'seoul', 'éŸ©'],
    'DE': ['de', 'germany', 'frankfurt', 'å¾·'],
    'GB': ['uk', 'gb', 'united kingdom', 'london', 'è‹±'],
    'RU': ['ru', 'russia', 'moscow', 'ä¿„'],
    'FR': ['fr', 'france', 'paris', 'æ³•'],
    'CA': ['ca', 'canada', 'åŠ '],
}

FLAG_MAP = {
    'HK': 'ğŸ‡­ğŸ‡°', 'JP': 'ğŸ‡¯ğŸ‡µ', 'US': 'ğŸ‡ºğŸ‡¸', 'SG': 'ğŸ‡¸ğŸ‡¬', 'TW': 'ğŸ‡¹ğŸ‡¼',
    'KR': 'ğŸ‡°ğŸ‡·', 'DE': 'ğŸ‡©ğŸ‡ª', 'GB': 'ğŸ‡¬ğŸ‡§', 'RU': 'ğŸ‡·ğŸ‡º', 'FR': 'ğŸ‡«ğŸ‡·', 'CA': 'ğŸ‡¨',
    'UNKNOWN': 'ğŸ³ï¸'
}

def get_content(url):
    try:
        print(f"[-] ä¸‹è½½ä¸­: {url}...", flush=True)
        # bulinkbulink è¿™ç§é GitHub é“¾æ¥æœ‰æ—¶å€™å“åº”æ…¢ï¼Œè®¾ç½® 15 ç§’è¶…æ—¶
        resp = requests.get(url, timeout=15)
        if resp.status_code == 200:
            return resp.text
        return ""
    except Exception as e:
        print(f"    [!] ä¸‹è½½å¼‚å¸¸: {e}", flush=True)
        return ""

def identify_country(text):
    text = text.lower()
    for code, keywords in KEYWORD_MAP.items():
        for kw in keywords:
            if kw in text:
                return code
    return 'UNKNOWN'

def rename_vmess(link):
    try:
        if not link.startswith("vmess://"): return link
        b64_str = link[8:]
        missing_padding = len(b64_str) % 4
        if missing_padding: b64_str += '=' * (4 - missing_padding)
        json_str = base64.b64decode(b64_str).decode('utf-8', errors='ignore')
        config = json.loads(json_str)
        original_ps = config.get('ps', '')
        address = config.get('add', '')
        country = identify_country(original_ps)
        if country == 'UNKNOWN': country = identify_country(address)
        flag = FLAG_MAP.get(country, 'ğŸ³ï¸')
        clean_ps = original_ps[:20] if original_ps else "Node"
        new_ps = f"{flag} {country} {clean_ps}"
        config['ps'] = new_ps
        new_json = json.dumps(config, ensure_ascii=False)
        new_b64 = base64.b64encode(new_json.encode('utf-8')).decode('utf-8')
        return f"vmess://{new_b64}"
    except:
        return link

def rename_url_struct(link):
    try:
        parsed = urllib.parse.urlparse(link)
        original_name = urllib.parse.unquote(parsed.fragment)
        host = parsed.hostname or ""
        country = identify_country(original_name)
        if country == 'UNKNOWN': country = identify_country(host)
        flag = FLAG_MAP.get(country, 'ğŸ³ï¸')
        name_clean = original_name[:20] if original_name else "Node"
        new_name = f"{flag} {country} {name_clean}"
        new_parsed = parsed._replace(fragment=urllib.parse.quote(new_name))
        return urllib.parse.urlunparse(new_parsed)
    except:
        return link

def process_nodes(content):
    processed_nodes = set()
    # 1. ä½¿ç”¨ä¿®å¤åçš„æ­£åˆ™æå–æ‰€æœ‰é“¾æ¥
    raw_links = re.findall(r'(?:vmess|vless|ss|trojan|hysteria2?)://[a-zA-Z0-9\-\._~%!$&\'()*+,;=:@/?#]+', content)
    
    for link in raw_links:
        if len(link) < 15: continue
        processed_nodes.add(link)

    # 2. å°è¯• Base64 è§£ç å¹¶æå–
    try:
        clean_content = content.replace(' ', '').replace('\n', '')
        if len(clean_content) % 4 != 0:
            clean_content += '=' * (4 - len(clean_content) % 4)
        decoded = base64.b64decode(clean_content).decode('utf-8', errors='ignore')
        decoded_links = re.findall(r'(?:vmess|vless|ss|trojan|hysteria2?)://[a-zA-Z0-9\-\._~%!$&\'()*+,;=:@/?#]+', decoded)
        for link in decoded_links:
            if len(link) < 15: continue
            processed_nodes.add(link)
    except:
        pass

    return processed_nodes

def main():
    print("=== å¢å¼ºç‰ˆè„šæœ¬å¼€å§‹è¿è¡Œ ===", flush=True)
    all_nodes = set()

    # 1. æŠ“å–é˜¶æ®µ
    for url in URLS:
        content = get_content(url)
        if not content: continue
        
        nodes = process_nodes(content)
        if nodes:
            print(f"    > æŠ“å–åˆ° {len(nodes)} ä¸ªåŸå§‹èŠ‚ç‚¹")
            all_nodes.update(nodes)

    total = len(all_nodes)
    print(f"--- æŠ“å–ç»“æŸï¼Œå…± {total} ä¸ªèŠ‚ç‚¹ ---")

    # 2. ç†”æ–­ä¸éšæœºé˜¶æ®µ
    # è®¾å®šæœ€å¤§ä¿ç•™èŠ‚ç‚¹æ•°ï¼Œå»ºè®® 3000ï¼Œè¶…è¿‡è¿™ä¸ªæ•°æ‰‹æœºä¼šå¡
    MAX_NODES = 3000
    node_list = list(all_nodes)
    
    if total > MAX_NODES:
        print(f"âš ï¸ èŠ‚ç‚¹çˆ†ç‚¸ (> {MAX_NODES})ï¼Œæ­£åœ¨æ‰§è¡ŒéšæœºæŠ½æ ·...", flush=True)
        random.shuffle(node_list) # å½»åº•æ‰“ä¹±
        node_list = node_list[:MAX_NODES] # åªå–å‰ 3000 ä¸ª
        print(f"âœ… å·²ä¿ç•™éšæœºçš„ {MAX_NODES} ä¸ªèŠ‚ç‚¹")
    
    # 3. é‡å‘½åé˜¶æ®µ (åªå¤„ç†é€‰ä¸­çš„èŠ‚ç‚¹ï¼ŒèŠ‚çœæ—¶é—´)
    print("æ­£åœ¨è¿›è¡Œé‡å‘½åå¤„ç†...", flush=True)
    final_nodes = []
    for link in node_list:
        if link.startswith("vmess://"):
            final_nodes.append(rename_vmess(link))
        else:
            final_nodes.append(rename_url_struct(link))

    # 4. ä¿å­˜é˜¶æ®µ
    final_text = "\n".join(final_nodes)
    
    with open("nodes_plain.txt", "w", encoding="utf-8") as f:
        f.write(final_text)

    final_base64 = base64.b64encode(final_text.encode('utf-8')).decode('utf-8')
    with open("subscribe.txt", "w", encoding="utf-8") as f:
        f.write(final_base64)
    
    print("=== æˆåŠŸç”Ÿæˆ subscribe.txt ===")

if __name__ == "__main__":
    main()
